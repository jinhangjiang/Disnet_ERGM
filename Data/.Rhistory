head(ex1029)
model = lm(wage~Education+Experience+Black+SMSA+Region, data = ex1029)
model = lm(Wage~Education+Experience+Black+SMSA+Region, data = ex1029)
summary(model)
install.packages("alr3")
library(alr3)
fuel2001 <- fuel2001
View(fuel2001)
m1 = lm(fuel2001$FuelC~., data = fuel2001)
summary(m1)
par(mfrow = c(2, 2))
plot(m1)
remove_spots <- which(row.names(fuel2001) %in% c("FL","TX","NY"))
no_tx_fl_ny <- fuel2001[-remove_spots,]
new_model <- lm(FuelC ~ Tax + Drivers + Income + log(Miles,10), no_tx_fl_ny)
summary(new_model)
summary(m1)
attach(fuel2001)
m1 = lm(fuel2001$FuelC~Tax + Drivers + Income + log(Miles,10), data = fuel2001)
summary(m1)
par(mfrow = c(2, 2))
plot(m1)
hist(fuel2001$FuelC)
m2 <- lm(log(FuelC) ~ Tax + Drivers + Income + log(Miles,10), no_tx_fl_ny)
summary(m2)
m2 <- lm(log(FuelC,10) ~ Tax + Drivers + Income + log(Miles,10), no_tx_fl_ny)
summary(m2)
m2 <- lm(log(FuelC) ~ Tax + Drivers + Income + log(Miles,10), no_tx_fl_ny)
summary(m2)
exp(coefficients(m2))
plot(m2)
par(mfrow = c(2, 2))
plot(m2)
load("D:/1Github/CSRtm/workspaces/Specificity_Scores.RData")
house_data <- read.csv("http://www.lock5stat.com/datasets/HomesForSale.csv")
log_price <- log(house_data$Price, 10)
m1<- lm(log_price~Size+Beds, data = house_data)
summary(m1)
m2<- lm(log_price~Size+Beds+Baths, data = house_data)
summary(m2)
m3<- lm(log_price~Size+Beds+Baths+State, data = house_data)
summary(m1)
summary(m3)
anova(m1,m2)
anova(m2,m3)
AIC(m1,m2,m3)
help(state.x77)
state_data <- data.frame(state.x77)
state_data
pairs(state_data)
no_alaska <- state_data[-2,]
inter_model <- lm(Life.Exp ~1,no_alaska)
forward_model <- step(inter_model,direction = "forward",scope = (~Population+Income+Illiteracy+Murder+HS.Grad+Frost+Area))
final<-lm(Life.Exp ~ Murder + HS.Grad + Frost + Population, data = no_alaska)
summary(final)
runif(1)
?pnorm
pnorm(15,14,2)-pnorm(10,14,2)
1-pnorm(18,14,2)
qnorm(0.84,14,2)
### when it refers to a posibility, it says the midle area, gotta add half of the missing sample back
### if we do not know the population SD, we have to get tstar
### sample size - 1 would be the second value
### this example is using 80% confidence and 16(n) sample size
qt(0.9,15)
?qt
qt(0.005,3000)
qt(0.005,15)
pnorm(14,15,3.863288754)
1-pnorm(14,15,3.863288754)
1-qnorm(14,15,3.863288754)
1-qnorm(0.005,15,3.863288754)
qnorm(0.005,15,3.863288754)
### when it refers to a posibility, it says the midle area, gotta add half of the missing sample back
### if we do not know the population SD, we have to get tstar
### sample size - 1 would be the second value
### this example is using 80% confidence and 16(n) sample size
qt(0.9,15)
?qt
qt(0.995,2999)
qt(-2,9)
### when it refers to a posibility, it says the midle area, gotta add half of the missing sample back
### if we do not know the population SD, we have to get tstar
### sample size - 1 would be the second value
### this example is using 80% confidence and 16(n) sample size
qt(1,15)
dt(1,9)
dt(1,9)-dt(-2,9)
pt(1,9)-dt(-2,9)
pt(1,9)
dt(-2,9)
rt(1,9)-rt(-2,9)
pt(1,9)
dt(1,9)
1-dt(1,9)
qt(1,9)
pt(1,9)
pt(1,10)
pt(1,10)-pt(-2,10)
pt(1,100)-pt(-2,100)
qt(-2,rt)
qt(-2,rt())
qt(0.68,20)
qt(0.68,3)
tstar <- qt(.975,34)
p_lb <- 66.56 - tstar*4.62*(1+1/sqrt(35))
p_ub <- 66.56 + tstar*4.62*(1+1/sqrt(35))
pred <- c(p_lb, p_ub)
pred
tstar<- qt(0.975,34)
uk_lb <- 66.56-tstar*4.62/sqrt(35)
uk_ub <- 66.56+tstar*4.62/sqrt(35)
a_uk <- c(uk_lb, uk_ub)
a_uk
tstar<- qt(0.975,34)
uk_lb <- 67.77-tstar*6.24/sqrt(35)
uk_ub <- 67.77+tstar*6.24/sqrt(35)
a_uk <- c(uk_lb, uk_ub)
a_uk
0.36-1.96*sqrt(0.36*0.64/900)
0.36+1.96*sqrt(0.36*0.64/900)
qt(0.975,60)
-0.02-0.39548*2.000298
-0.02+0.39548*2.000298
-0.02-1.96*sqrt((0.14^2/31)+(0.17^2/31))
-0.02+1.96*sqrt((0.14^2/31)+(0.17^2/31))
tstar <- qt(.975,59)
p_lb <- 95720 - tstar*22621*(1+1/sqrt(60))
p_ub <- 95720 + tstar*22621*(1+1/sqrt(60))
pred <- c(p_lb, p_ub)
pred
tstar<- qt(0.975,59)
uk_lb <- 95720-tstar*22621/sqrt(60)
uk_ub <- 95720+tstar*22621/sqrt(60)
a_uk <- c(uk_lb, uk_ub)
a_uk
tstar<- qt(0.975,66)
uk_lb <- 104474.6-tstar*20871.22/sqrt(67)
uk_ub <- 104474.6+tstar*20871.22/sqrt(67)
a_uk <- c(uk_lb, uk_ub)
a_uk
ConfidenceInterval = function(confidence,samplesize,average,stdDev){
tstar<- qt(confidence,samplesize-1)
uk_lb <- average-tstar*stdDev/sqrt(samplesize)
uk_ub <- average+tstar*stdDev/sqrt(samplesize)
a_uk <- c(uk_lb, uk_ub)
a_uk
}
ConfidenceInterval(0.975,67,104474.6,20871.22)
## Condidence Interval
ConfidenceInterval = function(confidence,samplesize,average,stdDev){
tstar<- qt(confidence,samplesize-1)
uk_lb <- average-tstar*stdDev/sqrt(samplesize)
uk_ub <- average+tstar*stdDev/sqrt(samplesize)
a_uk <- c(uk_lb, uk_ub)
a_uk
}
ConfidenceInterval(0.975,250,0.536,)
## Test statistic
Z<- (19.6-23)/(7.3/sqrt(227))
## approach 1
p_value<- pnorm(Z)
p_value
x<-1472.5
s<-833.477
t<-(x-1350)/(s/sqrt(100))
t
2*pt(-t,99)
library(MASS)
2+2
install.packages(c("caret", "networkD3", "node2vec", "reshape", "topicmodels"))
install.packages("igraph")
g <- graph.formula(1-2, 1-3, 2-3, 2-4, 3-5, 4-5, 4-6,4-7, 5-6, 6-7)
library("igraph")
g <- graph.formula(1-2, 1-3, 2-3, 2-4, 3-5, 4-5, 4-6,4-7, 5-6, 6-7)
V(g)
V(g)
plot(g)
install.packages("sand")
# CHUNK 1
g <- graph_from_literal(1-2, 1-3, 2-3, 2-4, 3-5, 4-5,
4-6, 4-7, 5-6, 6-7)
# CHUNK 2
V(g)
# CHUNK 3
E(g)
# CHUNK 4
print_all(g)
# CHUNK 5
plot(g)
# CHUNK 6
dg <- graph_from_literal(1-+2, 1-+3, 2++3)
plot(dg)
# CHUNK 7
dg <- graph_from_literal(Sam-+Mary, Sam-+Tom,
Mary++Tom)
print_all(dg)
plot(dg)
# CHUNK 8
V(dg)$name <- c("Sam", "Mary", "Tom")
# CHUNK 9
E(dg)
# CHUNK 10
as_adjacency_matrix(g)
# CHUNK 4
print_all(g)
str(g)
# CHUNK 4
print_all(g)
# CHUNK 3
E(g)
get.edgelist(g)
# CHUNK 10
as_adjacency_matrix(g)
# CHUNK 10
as_adjacency_matrix(g)
get.adjacency(g)
get.adjacency(dg)
# CHUNK 1
g <- graph_from_literal(1-2, 1-3, 2-3, 2-4, 3-5, 4-5,
4-6, 4-7, 5-6, 6-7)
# CHUNK 2
V(g)
vcount(g)
# CHUNK 3
E(g)
ecount(g)
# CHUNK 4
print_all(g)
# CHUNK 5
plot(g)
# CHUNK 1
g <- graph_from_literal(1-2, 1-3, 1-7, 3-4, 2-3, 2-4, 3-5, 4-5,
4-6, 4-7, 5-6, 5-8, 6-7, 7-8)
# CHUNK 2
V(g)
vcount(g)
# CHUNK 3
E(g)
ecount(g)
# CHUNK 4
print_all(g)
# CHUNK 5
plot(g)
# CHUNK 4
g$name <- "directed graph"
print_all(g)
# CHUNK 4
g$name <- "undirected graph"
print_all(g)
V(g)$name
V(g)$name <- c("Adam","Judy","Bobby","Sam","Frank","Jay","Tom","Jerry")
V(g)$name
# CHUNK 5
plot(g)
# CHUNK 7
dg <- graph_from_literal(JFK-+PEK, JFK+CDG,
PEK++CDG)
plot(dg)
print_all(dg)
get.adjacency(dg)
# CHUNK 10
get.adjedgelist(dg)
# CHUNK 7
dg <- graph_from_literal(JFK-+PEK, JFK-+CDG,
PEK++CDG)
plot(dg)
print_all(dg)
# CHUNK 8
V(dg)$name <- c("Sam", "Mary", "Tom")
# CHUNK 7
dg <- graph_from_literal(JFK-+PEK, JFK-+CDG,
PEK++CDG)
plot(dg)
print_all(dg)
# CHUNK 10
get.adjedgelist(dg)
# CHUNK 10
get.adjedgelist(g)
# CHUNK 10
get.adjlist(g)
get.edgelist(g)
get.adjacency(g)
# CHUNK 10
adjlist <- get.adjlist(g)
adjlist[1]
as.data.frame(get.edgelist(g))
as_adjacency_matrix(g)
# CHUNK 20
library(sand)
g.lazega <- graph_from_data_frame(elist.lazega,
directed="FALSE",
vertices=v.attr.lazega)
g.lazega$name <- "Lazega Lawyers"
plot(g.lazega)
# CHUNK 12
par(mfrow=c(1, 2))
h <- g - vertices(c(6,7))
# CHUNK 14
h1 <- h
h2 <- graph_from_literal(4-6, 4-7, 5-6, 6-7)
g <- union(h1,h2)
plot(h)
plot(g)
# CHUNK 1
g <- graph_from_literal(1-2, 1-3, 1-7, 3-4, 2-3, 2-4, 3-5, 4-5,
4-6, 4-7, 5-6, 5-8, 6-7, 7-8)
V(g)$name <- c("Adam","Judy","Bobby","Sam","Frank","Jay","Tom","Jerry")
# CHUNK 5
plot(g)
h <- g - vertices(c("Adam","Judy"))
# CHUNK 12
par(mfrow=c(1, 2))
# CHUNK 14
#h1 <- h
#h2 <- graph_from_literal(4-6, 4-7, 5-6, 6-7)
h2 <- g - vertices(c("Bobby","Sam","Frank","Jay","Tom","Jerry"))
# CHUNK 12
par(mfrow=c(1, 3))
h1 <- g - vertices(c("Adam","Judy"))
# CHUNK 14
#h1 <- h
#h2 <- graph_from_literal(4-6, 4-7, 5-6, 6-7)
h2 <- g - vertices(c("Bobby","Sam","Frank","Jay","Tom","Jerry"))
h3 <- union(h1,h2)
plot(h1)
plot(h2)
plot(h3)
# CHUNK 12
par(mfrow=c(2, 2))
h1 <- g - vertices(c("Adam","Judy"))
# CHUNK 14
#h1 <- h
#h2 <- graph_from_literal(4-6, 4-7, 5-6, 6-7)
h2 <- g - vertices(c("Bobby","Sam","Frank","Jay","Tom","Jerry"))
h3 <- union(h1,h2)
plot(g)
plot(h1)
plot(h2)
plot(h3)
# CHUNK 14
#h1 <- h
h2 <- graph_from_literal("Adam"-"Judy", "Adam"-"Bobby", "Adam"-"Sam", "Judy"-"Bobby","Judy"-"Frank")
h3 <- union(h1,h2)
plot(g)
plot(h1)
plot(h2)
plot(h3)
# CHUNK 5
plot(g)
plot(h1)
plot(h2)
plot(h3)
h3 <- h1 + h2
plot(g)
plot(g)
plot(g)
plot(g)
plot(g)
par(mfrow=c(2, 2))
plot(g)
plot(h1)
plot(h2)
plot(h3)
plot(g)
par(mfrow=c(2, 2))
plot(g)
plot(h1)
plot(h2)
plot(h3)
par(mfrow=c(2, 2))
plot(g)
plot(h1)
par(mfrow=c(2, 2))
plot(g)
par(mfrow=c(2, 2))
plot(g)
plot(h1)
plot(h2)
plot(h3)
par(mfrow=c(2, 2))
set.seed(1)
plot(g)
plot(h1)
plot(h2)
plot(h3)
par(mfrow=c(2, 2))
set.seed(1)
plot(g)
plot(h1)
plot(h2)
plot(h3)
par(mfrow=c(2, 2))
set.seed(2)
plot(g)
par(mfrow=c(2, 2))
set.seed(4)
plot(g)
plot(h1)
plot(h2)
plot(h3)
par(mfrow=c(1,1))
set.seed(4)
plot(g)
g.lazega <- graph_from_data_frame(elist.lazega,
directed="FALSE",
vertices=v.attr.lazega)
g.lazega$name <- "Lazega Lawyers"
plot(g.lazega)
vertex_attr_names(g.lazega)
install.packages(c("htmlwidgets", "knitr", "latticeExtra", "tergm", "tsna"))
install.packages("ndtv")
install.packages('ndtv')
library(knitr)
knitr::opts_chunk$set(cache=F, comment=NA, fig.align='center')
# statnet packages
install.packages('tergm')
install.packages('tsna')
install.packages('ndtv')
# other packages to enhance graphical output
install.packages('htmlwidgets')
install.packages('latticeExtra')
setwd("D:/1Github/Disnet_ERGM/Data")
library(ergm)
library(tidyverse)
library(network)
#packageVersion("ergm")
set.seed(0)
#?network
####### generate g1 ###########
icd10.g1 <- icd101[c("Id","Category","Prevalence_20192")]
edge.g1 <- edge1[c("Source","Target","Weight20192")]
start.time <- Sys.time()
g1 <- network(edge.g1[c("Source","Target")],directed = FALSE, vertices=icd10.g1)
delete.edges(g1, seq_along(g1$mel))
edge.g1 <- as.matrix(edge.g1, attrname="Weight20192",
matrix.type="edgelist")
?as.matrix
g1[edge.g1[ ,1:2], names.eval="weight", add.edges=TRUE,] <- as.numeric(edge.g1[,3])
#set.edge.attribute(g1,"weight",edge.g1$Weight20192)
summary(g1)
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
plot(g1)
####### generate g2 ###########
icd10.g2 <- icd102[c("Id","Category","Prevalence_20201")]
edge.g2 <- edge2[c("Source","Target","Weight20201")]
g2 <- network(edge.g2[c("Source","Target")],directed = FALSE, vertices=icd10.g2)
set.edge.attribute(g2,"weight",edge.g2$Weight20201)
#vertex_attr_names(g2)
####### generate g3 ###########
icd10.g3 <- icd103[c("Id","Category","Prevalence_20202")]
edge.g3 <- edge3[c("Source","Target","Weight20202")]
g3 <- network(edge.g3[c("Source","Target")],directed = FALSE, vertices=icd10.g3)
set.edge.attribute(g3,"weight",edge.g3$Weight20202)
library(readr)
edge1 <- read_csv("edge1.csv")
View(edge1)
library(readr)
edge2 <- read_csv("edge2.csv")
View(edge2)
library(readr)
edge3 <- read_csv("edge3.csv")
View(edge3)
library(readr)
icd101 <- read_csv("icd101.csv")
View(icd101)
library(readr)
icd102 <- read_csv("icd102.csv")
View(icd102)
library(readr)
icd103 <- read_csv("icd103.csv")
View(icd103)
View(edge1)
library(ergm)
library(tidyverse)
library(network)
#packageVersion("ergm")
set.seed(0)
#?network
####### generate g1 ###########
icd10.g1 <- icd101[c("Id","Category","Prevalence_20192")]
edge.g1 <- edge1[c("Source","Target","Weight20192")]
start.time <- Sys.time()
g1 <- network(edge.g1[c("Source","Target")],directed = FALSE, vertices=icd10.g1)
delete.edges(g1, seq_along(g1$mel))
edge.g1 <- as.matrix(edge.g1, attrname="Weight20192",
matrix.type="edgelist")
?as.matrix
g1[edge.g1[ ,1:2], names.eval="weight", add.edges=TRUE,] <- as.numeric(edge.g1[,3])
#set.edge.attribute(g1,"weight",edge.g1$Weight20192)
summary(g1)
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
plot(g1)
####### generate g2 ###########
icd10.g2 <- icd102[c("Id","Category","Prevalence_20201")]
edge.g2 <- edge2[c("Source","Target","Weight20201")]
g2 <- network(edge.g2[c("Source","Target")],directed = FALSE, vertices=icd10.g2)
set.edge.attribute(g2,"weight",edge.g2$Weight20201)
#vertex_attr_names(g2)
####### generate g3 ###########
icd10.g3 <- icd103[c("Id","Category","Prevalence_20202")]
edge.g3 <- edge3[c("Source","Target","Weight20202")]
g3 <- network(edge.g3[c("Source","Target")],directed = FALSE, vertices=icd10.g3)
set.edge.attribute(g3,"weight",edge.g3$Weight20202)
V(g1)
summary(g1)
####### estimate  g1 model ###########
help("ergm-references")
